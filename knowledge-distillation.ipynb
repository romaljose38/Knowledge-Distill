{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-15T09:19:10.393369Z",
     "iopub.status.busy": "2023-10-15T09:19:10.393052Z",
     "iopub.status.idle": "2023-10-15T09:19:10.850580Z",
     "shell.execute_reply": "2023-10-15T09:19:10.849553Z",
     "shell.execute_reply.started": "2023-10-15T09:19:10.393341Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T09:19:10.852569Z",
     "iopub.status.busy": "2023-10-15T09:19:10.851963Z",
     "iopub.status.idle": "2023-10-15T09:19:21.862426Z",
     "shell.execute_reply": "2023-10-15T09:19:21.861215Z",
     "shell.execute_reply.started": "2023-10-15T09:19:10.852539Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, MaxPool2D, BatchNormalization, Input, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import h5py\n",
    "from IPython.display import display\n",
    "from PIL import Image as im\n",
    "import datetime\n",
    "import random\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T09:23:13.641088Z",
     "iopub.status.busy": "2023-10-15T09:23:13.639805Z",
     "iopub.status.idle": "2023-10-15T09:23:13.648778Z",
     "shell.execute_reply": "2023-10-15T09:23:13.647523Z",
     "shell.execute_reply.started": "2023-10-15T09:23:13.641041Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainGenerator(batch_size, train_path):\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255, rotation_range=5, shear_range=0.02, zoom_range=0.1,\n",
    "                                       brightness_range=[0.7,1.3],  horizontal_flip=True,\n",
    "                                         vertical_flip=True, fill_mode='nearest')\n",
    "    train_gen = datagen.flow_from_directory(train_path, batch_size=batch_size,target_size=(224, 224), shuffle=True, seed=1, class_mode=\"categorical\" )\n",
    "    for image, label in train_gen:\n",
    "        yield (image, label)\n",
    "        \n",
    "def validGenerator(batch_size, valid_path):\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255, )\n",
    "    valid_gen = datagen.flow_from_directory(valid_path, batch_size=batch_size, target_size=(224, 224),shuffle=True, seed=1 )\n",
    "    for image, label in valid_gen:\n",
    "        yield (image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T09:23:27.046110Z",
     "iopub.status.busy": "2023-10-15T09:23:27.045684Z",
     "iopub.status.idle": "2023-10-15T09:23:27.053677Z",
     "shell.execute_reply": "2023-10-15T09:23:27.052345Z",
     "shell.execute_reply.started": "2023-10-15T09:23:27.046083Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T09:24:00.355332Z",
     "iopub.status.busy": "2023-10-15T09:24:00.354843Z",
     "iopub.status.idle": "2023-10-15T09:24:03.752383Z",
     "shell.execute_reply": "2023-10-15T09:24:03.751224Z",
     "shell.execute_reply.started": "2023-10-15T09:24:00.355297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = VGG16(input_shape = (224, 224, 3), include_top=False, weights=\"imagenet\")#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-15T09:24:56.007126Z",
     "iopub.status.busy": "2023-10-15T09:24:56.006562Z",
     "iopub.status.idle": "2023-10-15T09:24:56.252501Z",
     "shell.execute_reply": "2023-10-15T09:24:56.251098Z",
     "shell.execute_reply.started": "2023-10-15T09:24:56.007085Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               12845568  \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 1539      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,561,795\n",
      "Trainable params: 27,006,467\n",
      "Non-trainable params: 555,328\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for layer in base_model.layers[:8]:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = layers.Flatten()(base_model.output)\n",
    "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "#x = layers.BatchNormalization()(x)\n",
    "# Add a dropout rate of 0.5\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(3)(x)   #linear activation to get pre-soft logits\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "opti = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(optimizer = opti, loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics='acc')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
    "filepath=\"model_save/weights-{epoch:02d}-{val_accuracy:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks = [earlystop ]\n",
    "vgg_hist = model.fit(train_generator, validation_data = validation_generator, validation_steps=10, \n",
    "                    steps_per_epoch = 90, epochs = 50, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.figure(1)  \n",
    "# summarize history for accuracy\n",
    "plt.subplot(211)\n",
    "plt.plot(vgg_hist.history['acc'])\n",
    "plt.plot(vgg_hist.history['val_acc'])\n",
    "plt.title('teacher model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='lower right')\n",
    " # summarize history for loss\n",
    "plt.subplot(212)\n",
    "plt.plot(vgg_hist.history['loss'])\n",
    "plt.plot(vgg_hist.history['val_loss'])\n",
    "plt.title('teacher model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "test_dir = '/content/test'\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    files = np.array(data['filenames'])\n",
    "    targets = np.array(data['target'])\n",
    "    target_labels = np.array(data['target_names'])\n",
    "    return files,targets,target_labels\n",
    "x_test, y_test,target_labels = load_dataset(test_dir)\n",
    "from keras.utils import np_utils\n",
    "y_test = np_utils.to_categorical(y_test,no_of_classes)\n",
    "# We just have the file names in the x set. Let's load the images and convert them into array.\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "def convert_image_to_array(files):\n",
    "    images_as_array=[]\n",
    "    for file in files:\n",
    "        # Convert to Numpy Array\n",
    "        images_as_array.append(tf.image.resize(img_to_array(load_img(file)), (224, 224)))\n",
    "    return images_as_array\n",
    "x_test = np.array(convert_image_to_array(x_test))\n",
    "print('Test set shape : ',x_test.shape)\n",
    "x_test = x_test.astype('float32')/255\n",
    "# Let's visualize test prediction.\n",
    "y_pred_logits = model.predict(x_test)\n",
    "y_pred = tf.nn.softmax(y_pred_logits)\n",
    "# plot a raandom sample of test images, their predicted labels, and ground truth\n",
    "fig = plt.figure(figsize=(16, 9))\n",
    "for i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(np.squeeze(x_test[idx]))\n",
    "    pred_idx = np.argmax(y_pred[idx])\n",
    "    true_idx = np.argmax(y_test[idx])\n",
    "    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n",
    "                 color=(\"green\" if pred_idx == true_idx else \"red\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary layers  \n",
    "from tensorflow.keras.layers import Input, Conv2D \n",
    "from tensorflow.keras.layers import MaxPool2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras import Model\n",
    "# input\n",
    "input = Input(shape =(224,224,3))\n",
    "# 1st Conv Block\n",
    "x = Conv2D (filters =8, kernel_size =3, padding ='valid', activation='relu')(input)\n",
    "x = Conv2D (filters =8, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='valid')(x)\n",
    "# 2nd Conv Block\n",
    "x = Conv2D (filters =16, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "x = Conv2D (filters =16, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='valid')(x)\n",
    "# 3rd Conv block\n",
    "x = Conv2D (filters =32, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "x = Conv2D (filters =32, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "#x = Conv2D (filters =32, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='valid')(x)\n",
    "# 4th Conv block\n",
    "x = Conv2D (filters =64, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "x = Conv2D (filters =64, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "#x = Conv2D (filters =64, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='valid')(x)\n",
    "# 5th Conv block\n",
    "x = Conv2D (filters =64, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "x = Conv2D (filters =64, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "#x = Conv2D (filters =64, kernel_size =3, padding ='valid', activation='relu')(x)\n",
    "x = MaxPool2D(pool_size =2, strides =2, padding ='valid')(x)\n",
    "# Fully connected layers\n",
    "x = Flatten()(x)\n",
    "#x = Dense(units = 1028, activation ='relu')(x)\n",
    "x = Dense(units = 256, activation ='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(units = 3)(x)   #last layer with linear activation\n",
    "# creating the model\n",
    "s_model_1 = Model (inputs=input, outputs =output)\n",
    "s_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.5,\n",
    "        temperature=2,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller.\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "        \"\"\"\n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "    def train_step(self, data):\n",
    "        # Unpack data\n",
    "        x, y = data\n",
    "        # Forward pass of teacher\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        #model = ...  # create the original model\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student\n",
    "            # Forward pass of student\n",
    "            student_predictions = self.student(x, training=True)\n",
    "            # Compute losses\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.softmax(teacher_predictions / self.temperature, axis=1),\n",
    "                tf.nn.softmax(student_predictions / self.temperature, axis=1),\n",
    "            )\n",
    "            loss = self.alpha * student_loss +  distillation_loss\n",
    "        # Compute gradients\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # Update the metrics configured in `compile()`.\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data\n",
    "        x, y = data\n",
    "        # Compute predictions\n",
    "        y_prediction = self.student(x, training=False)\n",
    "        # Calculate the loss\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "        # Return a dict of performance\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller = Distiller(student=s_model_1, teacher=model)\n",
    "distiller.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.001),\n",
    "    metrics=['acc'],\n",
    "    student_loss_fn=CategoricalCrossentropy(from_logits=True),\n",
    "distillation_loss_fn=tf.keras.losses.KLDivergence(),\n",
    "    alpha=0.5,\n",
    "    temperature=2,\n",
    ")\n",
    "# Distill teacher to student\n",
    "distiller_hist = distiller.fit(train_generator, validation_data = validation_generator, epochs=50, validation_steps=10,\n",
    "              steps_per_epoch = 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)  \n",
    "# summarize history for accuracy  \n",
    "plt.subplot(211)  \n",
    "plt.plot(distiller_hist.history['acc'])  \n",
    "plt.plot(distiller_hist.history['val_acc'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid'], loc='lower right')  \n",
    " # summarize history for loss  \n",
    "plt.subplot(212)  \n",
    "plt.plot(distiller_hist.history['student_loss'])  \n",
    "plt.plot(distiller_hist.history['val_student_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'valid'], loc='upper right')  \n",
    "plt.show()\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distiller.metrics_names)\n",
    "acc, loss = distiller.evaluate(x_test, y_test, verbose = 1) \n",
    "print('test loss = ', loss)\n",
    "print('test accuracy = ',acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
